<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0">
    <title>EU AI Act Code of Practice</title>
    <link rel="stylesheet" href="https://edwardtufte.github.io/tufte-css/tufte.css" />
    <link rel="stylesheet" href="styles.css" />
</head>

<body>
    <article role="main">
        <!-- Navigation toggle -->
        <button class="nav-toggle" aria-expanded="false" aria-controls="side-nav" aria-label="Toggle navigation menu">
            <span class="nav-icon" aria-hidden="true">&#9776;</span>
            <span class="nav-label">Table of Contents</span>
        </button>

        <!-- Navigation -->
        <nav id="side-nav" class="side-nav" role="navigation" aria-label="Table of contents">
            <div class="nav-controls">
                <div class="theme-control">
                    <label for="theme-select">Theme:</label>
                    <select id="theme-select" aria-label="Select color theme">
                        <option value="system">üñ•Ô∏è System Default</option>
                        <option value="light">‚òÄÔ∏è Light</option>
                        <option value="dark">üåô Dark</option>
                    </select>
                </div>
            </div>
            <div class="keyboard-shortcuts" aria-label="Keyboard shortcuts">
                <h4>Keyboard Shortcuts</h4>
                <ul>
                    <li><kbd>‚Üë</kbd>/<kbd>‚Üì</kbd> Navigate headlines</li>
                    <li><kbd>‚Üê</kbd>/<kbd>‚Üí</kbd> Navigate commitments</li>
                    <li><kbd>1</kbd>To top<kbd>2</kbd>To glossary</li>
                    <li><kbd>3</kbd>To recitals<kbd>4</kbd>Toggle all recitals</li>
                </ul>
            </div>
            <div id="nav-content" class="nav-content">
            </div>
        </nav>

        <h1>EU AI Act Code of Practice</h1>

        <section class="main-content" aria-label="Main content">
            <p class="subtitle">Second Draft - 19/12/2024</p>

            <div class="disclaimer-box" role="complementary" aria-label="Important disclaimer">
                <h4>IMPORTANT DISCLAIMER & HOW TO CONTRIBUTE</h4>
                <p>This is a free, best-effort service to make the EU AI Act Code of Practice more accessible to
                    stakeholders. While we strive
                    for accuracy, this is NOT an official source.</p>

                <p><strong>Please always refer to the <a
                            href="https://digital-strategy.ec.europa.eu/en/library/second-draft-general-purpose-ai-code-practice-published-written-independent-experts">official
                            PDF document</a> for the authoritative version.</strong> Any discrepancies between this
                    version and the official document should be considered errors on our part.</p>

                <p>Help us improve:</p>
                <ul>
                    <li>Report errors via email: <a
                            href="mailto:alexander.zacherl@googlemail.com">alexander.zacherl@googlemail.com</a></li>
                    <li>Submit a pull request on <a href="https://github.com/yourusername/cop-reader">GitHub</a></li>
                </ul>
            </div>

            <h2>Opening statement by the Chairs and Vice-Chairs</h2>

            <p>As the Chairs and Vice-Chairs of the four Working Groups, we hereby present the second draft of the
                General-Purpose AI Code of Practice under the AI Act (the "Code"). Participants in the Working Groups
                and observers of the Code of Practice Plenary are welcome to submit written feedback on this draft by 15
                January 2025 via a dedicated survey shared with them.</p>

            <p>We would like to emphasise that the second draft remains a work-in-progress. Given the short timeframe
                between receiving feedback on the first draft and publishing this second draft, we have focused
                primarily on providing clarifications, adding essential details, and refining our approach to
                proportionality.</p>

            <p>Incorporation of specific feedback at this stage does not guarantee its inclusion in the final Code ‚Äì we
                will have more time to carefully discuss and evaluate various Commitments and Measures before the third
                draft, and significant updates will likely occur. Conversely, where certain elements remain unchanged in
                this draft, this does not indicate permanence ‚Äì we simply may not have addressed these aspects yet.</p>

            <p>This second draft of the Code addresses key considerations for providers of general-purpose AI models and
                providers of general-purpose AI models with systemic risk when complying with Chapter V of the AI Act,
                through four Working Groups working in close collaboration:</p>
            <ul>
                <li>Working Group 1: Transparency and copyright-related rules</li>
                <li>Working Group 2: Risk assessment for systemic risk</li>
                <li>Working Group 3: Technical risk mitigation for systemic risk</li>
                <li>Working Group 4: Governance risk mitigation for systemic risk</li>
            </ul>

            <p>Working Group 1 Transparency applies to all general-purpose AI models, except for those that are released
                under a free and open-source licence satisfying the conditions specified in Article 53(2) AI Act and not
                classified as general-purpose AI models with systemic risk. Working Group 1 Copyright applies to all
                general-purpose AI models. Working Groups 2, 3, and 4, along with the corresponding Section III only
                apply to providers of general-purpose AI models classified as general-purpose AI models with systemic
                risk based on Article 51 AI Act.</p>

            <p>Following a thorough review of the feedback received by stakeholders on the first draft, we have refined
                Commitments and Measures and expanded the Code's provisions while maintaining its Objectives. We present
                this second draft as a foundation for further development. The next draft will draw on your feedback
                provided via the EU survey, in provider workshops, and in Working Group meetings. Thus far, we have
                found your feedback extremely helpful, resulting in substantial changes. We therefore encourage
                stakeholders to continue providing comprehensive feedback on all aspects of the Code, including both new
                and unchanged elements. Your feedback will help shape the final version of the Code, which will play a
                crucial role in guiding the future of general-purpose AI model development and deployment.</p>

            <p>We have once again included a high-level drafting plan which outlines our guiding principles for the
                Code, and the assumptions it is based on. While we continue to engage in thorough deliberations
                regarding specific Commitments, Measures and Key Performance Indicators (KPIs), we hope the drafting
                plan provides stakeholders clarity on the potential form and content of the final Code.</p>

            <p>Note that the exemplary KPIs included in this version of the Code are preliminary, and subject to review
                and revision. For example, while some are quantitative, others are more qualitative. Thus, we strongly
                encourage, and welcome, feedback on the KPIs.</p>

            <p>The AI Act came into force on 1 August 2024, stating that the final version of the Code should be ready
                by 2 May 2025. The second draft builds upon previous work while aiming to provide a "future-proof" Code,
                appropriate for the next generation of models which will be developed and released in 2025 and
                thereafter.</p>

            <p>In formulating this second draft, we have been principally guided by the provisions in the AI Act as to
                matters within the scope of the Code. Accordingly, unless the context and definition contained within
                the Code indicates otherwise, the terms used in the Code refer to identical terms from the AI Act. We
                have not included exhaustive references to provisions in the AI Act in this second draft but expect to
                do so in future iterations.</p>

            <p>Like the first draft, this document is the result of a collaborative effort involving hundreds of
                participants from across industry, academia, and civil society. It has been informed by feedback
                received in response to the first draft, which has been insightful and instructive in our drafting
                process. We continue to be informed by the evolving literature on AI governance, international
                approaches (as specified in Article 56(1) AI Act), Union law codes of practice (such as the Code of
                Practice on Disinformation), industry best practice, and the expertise and experience of providers and
                Working Group members.</p>

            <h3>Key features of the development process of the Code include:</h3>
            <ul>
                <li>Drafted by Chairs and Vice-Chairs who were selected by the AI Office for their expertise,
                    experience, independence (including absence of financial interests), and to ensure gender and
                    geographic diversity.</li>
                <li>A multi-stakeholder consultation which closed in September and received 427 submissions</li>
                <li>A multi-stakeholder survey on the first draft of the Code which received 354 submissions, with more
                    surveys to come</li>
                <li>Organisational support and legal advice from the AI Office</li>
                <li>Provider workshops led by Chairs and Vice-Chairs</li>
                <li>Four specialised Working Group meetings led by Chairs and Vice-Chairs</li>
                <li>Meetings with representatives from EU Member States in the AI Board and from the European Parliament
                </li>
            </ul>

            <p>Additional time for consultation and deliberation ‚Äì both externally and internally ‚Äì will be needed to
                refine and improve the current draft. As a group of independent Chairs and Vice-Chairs, we strive to
                make this process as transparent and accessible to stakeholders as possible, aiming to share our work
                and our thinking as early as possible, while taking sufficient time to coordinate and discuss key
                questions within Working Groups. We count on your continued engaged collaboration and constructive
                criticism.</p>

            <p>Finally, we wish to highlight that, at this stage in the drafting process, one of our central priorities
                has been to clearly communicate our motivations and reasoning regarding the issues we are addressing.
                Many of these issues are nuanced and complex, and we aim to convey them transparently through the draft
                text of the Code. Further, we used our time mainly to refine Commitments, Measures, and KPIs, rather
                than ensuring all the parts of the Code seamlessly fit together and are easy to understand. We will work
                to improve these aspects in subsequent iterations to strengthen the Code.</p>

            <p>We welcome written feedback by the Code of Practice Plenary participants and observers by 15 January
                2025, via a dedicated survey shared with them.</p>

            <p>Thank you for your support!</p>

            <div class="signatures">
                <div class="signatures-grid">
                    <div class="signature-column">
                        <div class="signature-cell">
                            <div class="name">Nuria Oliver</div>
                            <div class="group">Working Group 1</div>
                            <div class="role">Co-Chair</div>
                        </div>
                        <div class="signature-cell">
                            <div class="name">Rishi Bommasani</div>
                            <div class="group">Working Group 1</div>
                            <div class="role">Vice-Chair</div>
                        </div>
                    </div>
                    <div class="signature-column">
                        <div class="signature-cell">
                            <div class="name">Alexander Peukert</div>
                            <div class="group">Working Group 1</div>
                            <div class="role">Co-Chair</div>
                        </div>
                        <div class="signature-cell">
                            <div class="name">C√©line Castets-Renard</div>
                            <div class="group">Working Group 1</div>
                            <div class="role">Vice-Chair</div>
                        </div>
                    </div>
                    <div class="signature-column">
                        <div class="signature-cell">
                            <div class="name">Matthias Samwald</div>
                            <div class="group">Working Group 2</div>
                            <div class="role">Chair</div>
                        </div>
                        <div class="signature-cell">
                            <div class="name">Marta Ziosi</div>
                            <div class="group">Working Group 2</div>
                            <div class="role">Vice-Chair</div>
                        </div>
                        <div class="signature-cell">
                            <div class="name">Alexander Zacherl</div>
                            <div class="group">Working Group 2</div>
                            <div class="role">Vice-Chair</div>
                        </div>
                    </div>
                    <div class="signature-column">
                        <div class="signature-cell">
                            <div class="name">Yoshua Bengio</div>
                            <div class="group">Working Group 3</div>
                            <div class="role">Chair</div>
                        </div>
                        <div class="signature-cell">
                            <div class="name">Daniel Privitera</div>
                            <div class="group">Working Group 3</div>
                            <div class="role">Vice-Chair</div>
                        </div>
                        <div class="signature-cell">
                            <div class="name">Nitarshan Rajkumar</div>
                            <div class="group">Working Group 3</div>
                            <div class="role">Vice-Chair</div>
                        </div>
                    </div>
                    <div class="signature-column">
                        <div class="signature-cell">
                            <div class="name">Marietje Schaake</div>
                            <div class="group">Working Group 4</div>
                            <div class="role">Chair</div>
                        </div>
                        <div class="signature-cell">
                            <div class="name">Anka Reuel</div>
                            <div class="group">Working Group 4</div>
                            <div class="role">Vice-Chair</div>
                        </div>
                        <div class="signature-cell">
                            <div class="name">Markus Anderljung</div>
                            <div class="group">Working Group 4</div>
                            <div class="role">Vice-Chair</div>
                        </div>
                    </div>
                </div>
            </div>

            <h2>Drafting plan, principles, and assumptions</h2>

            <p>This second draft provides more detailed provisions and concrete examples. At this stage, it still does
                not contain the level of granularity, especially for the KPIs, that we expect to include in the final
                adopted version of the Code. This is because:</p>
            <ul>
                <li>we are still working to achieve broad agreement on the structure and principles of the Code;</li>
                <li>there has been insufficient time to produce a more detailed proposal; and</li>
                <li>we will update the details within the Code on an ongoing basis, to reflect the latest developments
                    and advances in AI.</li>
            </ul>

            <p>The commitments outlined in this Code are organised in a descending hierarchy of Commitments, Measures,
                and KPIs. If any of these elements are absent, particularly KPIs, this is not a definitive decision but
                rather a consequence of the time limitations encountered during the development of this second draft.
                Moreover, this draft does not yet contain a section on how the Code will be reviewed and updated, which
                will be present in later iterations of the draft Code.</p>

            <h3>Below are some high-level principles we follow when drafting the Code:</h3>

            <ol>
                <li><strong>Alignment with EU Principles and Values</strong> ‚Äì Commitments, Measures, and KPIs will be
                    in line with general principles and values of the Union, as enshrined in EU law, including the
                    Charter of Fundamental Rights of the European Union, the Treaty on European Union, and Treaty on the
                    Functioning of the European Union.</li>

                <li><strong>Alignment with AI Act and International Approaches</strong> ‚Äì Commitments, Measures, and
                    KPIs will contribute to a proper application of the AI Act. This includes taking into account
                    international approaches (including standards or metrics developed by AI Safety Institutes, or
                    standard-setting organisations), in accordance with Article 56(1) AI Act.</li>

                <li><strong>Proportionality to Risks</strong> ‚Äì Commitments, Measures, and KPIs should be proportionate
                    to risks, meaning they should be:
                    <ul>
                        <li>suitable to achieve the desired end,</li>
                        <li>necessary to achieve the desired end, and</li>
                        <li>should not impose a burden that is excessive in relation to the end sought to be achieved.
                        </li>
                    </ul>
                    Some concrete applications of proportionality include:
                    <ol type="a">
                        <li>Commitments, Measures, and KPIs should be more stringent for higher risk tiers or uncertain
                            risks of severe harm. The Code can accomplish this by, for example, suggesting multiple KPIs
                            for each Measure related to a severe risk, thereby requiring providers of general-purpose AI
                            models to take action to mitigate that severe risk or to robustly demonstrate an extremely
                            rare likelihood of severe risk eventuating. The Code might also tie risk-mitigating Measures
                            to risk-assessment KPIs, including through the use of "if-then" requirements. For example,
                            if a general-purpose AI model with systemic risk is assessed to have capability X,
                            Signatories commit to putting in place Y risk mitigations, tracked by Z KPIs.</li>

                        <li>Measures and KPIs should be specific. While Commitments may be articulated at a higher level
                            of generality, general-purpose AI model providers should have a clear understanding of how
                            to meet Measures, tracked by KPIs as appropriate. Measures and KPIs should be designed to be
                            effective and robust against misspecification or any attempts of circumvention. The Code
                            strives to accomplish this by, for example, avoiding unnecessary use of proxy terms or
                            metrics. The AI Office will monitor and review Measures and KPIs that may be susceptible to
                            circumvention and other forms of misspecification.</li>

                        <li>Commitments, Measures, and KPIs should differentiate, where applicable, between different
                            types of risks, distribution strategies and deployment contexts of the concerned
                            general-purpose AI model, and other factors that may influence the tiers of risk, and how
                            risks need to be assessed and mitigated. For example, Commitments, Measures, and KPIs
                            assessing and mitigating systemic risks might need to differentiate between intentional and
                            unintentional risks, including instances of misalignment. Additionally, Commitments may need
                            to be adapted to take into account the different tools providers have available to assess
                            and mitigate systemic risk where model weights are freely released.</li>
                    </ol>
                </li>

                <li><strong>Future-Proof</strong> ‚Äì AI technology is changing rapidly. Measures and KPIs should maintain
                    the AI Office's ability to improve its assessment of compliance based on new information. Therefore,
                    the Code shall strive to facilitate the rapid updating of Measures and KPIs, as appropriate. It is
                    important to find a balance between specific requirements and performance indicators on one side,
                    and the flexibility to adapt rapidly to technological and industry developments on the other. The
                    Code can accomplish this by, for example, referencing dynamic sources of information that providers
                    can be expected to monitor and consider in their risk assessment and mitigation.
                    <p>Examples of such sources could include incident databases, consensus standards, up-to-date risk
                        registers, state-of-the-art risk management frameworks, and AI Office guidance. As technology
                        evolves, it may also be necessary to articulate an additional set of Measures and KPIs for
                        specific general-purpose AI models, for example, models used in agentic AI systems.</p>
                </li>

                <li><strong>Proportionality to the size of the general-purpose AI model provider</strong> ‚Äì Measures and
                    KPIs related to the obligations applicable to providers of general-purpose AI models should take due
                    account of the size of the general-purpose AI model provider and allow simplified ways of compliance
                    for small and medium enterprises (SMEs) and start-ups with fewer financial resources than those at
                    the frontier of AI development, where appropriate. KPIs related to the obligations applicable to
                    providers of general-purpose AI models with systemic risk shall also reflect differences in size and
                    capacity of providers, where appropriate.</li>

                <li><strong>Support and growth of the ecosystem for safe, human centric and trustworthy AI</strong> ‚Äì We
                    recognise that the development, adoption, and governance of general-purpose AI models are global
                    issues. Many Commitments in this draft are intended to enable and support cooperation between
                    different stakeholders, for example by sharing general-purpose AI safety infrastructure and best
                    practices amongst model providers, or by encouraging the participation of civil society, academia,
                    third parties, and government organisations in evidence collection. We promote further transparency
                    between stakeholders and increased efforts to share knowledge and cooperate in building a collective
                    and robust evidence base for safe, human centric and trustworthy AI in line with Article 56(1)(3),
                    Recital 1, and Recital 116 AI Act. We also acknowledge the positive impact that open-source models
                    have had on the development of safe, human centric and trustworthy AI.</li>

                <li><strong>Innovation of AI governance and risk management</strong> ‚Äì We recognise that determining the
                    most effective methods for understanding and ensuring the safety of general-purpose AI models
                    remains an evolving challenge. The Code should encourage providers to compete in and advance the
                    state-of-the-art in AI safety governance and related evidence collection methods and practices. When
                    providers can demonstrate equal or superior safety outcomes through alternative approaches that are
                    less burdensome, these innovations should be recognised as improving the state of the art of AI
                    governance and evidence and we should support their wider adoption.</li>
            </ol>

            <p>The current draft is written under the assumption that there will only be a small number of both
                general-purpose AI models with systemic risk and providers thereof. Should that assumption prove wrong,
                future drafts may need to be changed significantly, for instance, by introducing a more detailed tiered
                system of Commitments aiming to focus primarily on those models that provide the largest or most severe
                systemic risks. In particular, we want to highlight that even if modifications of general-purpose AI
                models increase the number of providers in scope, the modifiers' obligations under Articles 53 and 55 AI
                Act should be limited to the extent of their respective modifications, as appropriate. We expect more
                clarifications from the AI Office on these points, as stated in its <a
                    href="https://digital-strategy.ec.europa.eu/en/faqs/general-purpose-ai-models-ai-act-questions-answers">dedicated
                    Q&A</a>.</p>

            <h2>I. PREAMBLE</h2>

            <h3>Whereas:</h3>
            <ol type="a">
                <li>The Signatories of this Code of Practice (Code) recognise the importance of improving the
                    functioning of the internal market, of creating a level playing field for the regulation of
                    human-centric and trustworthy artificial intelligence (AI), while ensuring a high level of
                    protection of health, safety, fundamental rights enshrined in the Charter, including democracy, the
                    rule of law and environmental protection, against harmful effects of AI in the Union and supporting
                    innovation as emphasised in Article 1(1) AI Act. The Code shall be interpreted in this context.</li>

                <li>Whenever the Code refers to providers of general-purpose AI models it shall encompass providers of
                    general-purpose AI models with systemic risk, too. Whenever the Code refers to providers of
                    general-purpose AI models with systemic risk it shall not encompass providers of other
                    general-purpose AI models.</li>

                <li>The Signatories recognise that the Code serves as a guiding document for providers of
                    general-purpose AI models and general-purpose AI models with systemic risk in demonstrating
                    compliance with the AI Act, while recognising that adherence to this Code does not constitute
                    conclusive evidence of compliance with the AI Act.</li>

                <li>The Signatories recognise the importance of reporting their implementation of the Code and its
                    outcomes to facilitate the regular monitoring and evaluation of the Code's adequacy by the AI Office
                    and the Board (Article 56(5) AI Act).</li>

                <li>The Signatories recognise that the Code shall be subject to regular review by the AI Office. The AI
                    Office may encourage and facilitate updates of the Code to reflect advances in AI technology,
                    societal changes, and emerging systemic risks (Article 56(6) AI Act).</li>

                <li>The Signatories recognise that the Code may serve as a bridge until the adoption of harmonised EU
                    standards for general-purpose AI models. Updates may be needed to facilitate a gradual transition
                    towards future standards.</li>

                <li>The Signatories recognise that the absence of specific Commitments, Measures, and Key Performance
                    Indicators (KPIs) within this Code does not absolve providers of general-purpose AI models with
                    systemic risk from their responsibility to address and mitigate potential systemic risks as they
                    emerge.</li>

                <li>The Signatories recognise the importance of working in partnership with the AI Office to foster
                    collaboration between providers of general-purpose AI models, researchers, and regulatory bodies to
                    address emerging challenges and opportunities in the AI landscape.</li>
            </ol>

            <h3>The Objectives of the Code are as follows:</h3>
            <ol type="I">
                <li>Providers of general-purpose AI models can effectively comply with their obligations under the AI
                    Act. The Code of Practice should clarify to providers how to demonstrate compliance. The Code should
                    also enable the AI Office to assess the compliance of providers who choose to rely on the Code to
                    demonstrate compliance, in accordance with Articles 53(4) and 55(2) AI Act. This can include
                    allowing sufficient visibility into trends in the development and deployment of general-purpose AI
                    models, particularly of the most advanced models.</li>

                <li>Providers of general-purpose AI models can effectively ensure a good understanding of
                    general-purpose AI models along the AI value chain, both to enable the integration of such models
                    into downstream products and to fulfil subsequent obligations under the AI Act or other regulations
                    (see Article 53 and Recital 101 AI Act).</li>

                <li>Providers of general-purpose AI models can effectively comply with Union law on copyright and
                    related rights (see Article 53 and Recital 106 AI Act).</li>

                <li>Providers of general-purpose AI models with systemic risk can effectively continuously assess and
                    mitigate possible systemic risks at the Union level, including their sources, that may stem from the
                    development, the placing on the market, or the use of general-purpose AI models with systemic risk
                    (see Article 55 and Recital 114 AI Act).</li>
            </ol>

            <h2>II. COMMITMENTS BY PROVIDERS OF GENERAL-PURPOSE AI MODELS</h2>

            <h3>Whereas:</h3>
            <ol type="a">
                <li>The Signatories recognise the particular role and responsibility of providers of general-purpose AI
                    models along the AI value chain, as the models they provide may form the basis for a range of
                    downstream systems, often provided by downstream providers that need significant understanding of
                    the models and their capabilities, both to enable the integration of such models into their products
                    and to fulfil their obligations under the AI Act (see Recital 101 AI Act).</li>

                <li>The Signatories recognise that in the case of a modification or fine-tuning of a model, the
                    obligations for providers should be limited to that modification or fine-tuning to safeguard
                    proportionality (see Recital 109 AI Act).</li>

                <li>The AI Act and the Code are without prejudice to the rules laid down by Union and national law, and
                    the Code shall be interpreted in particular in accordance with Union copyright law. Directive (EU)
                    2019/790 introduced exceptions and limitations allowing reproductions and extractions of works or
                    other subject matter, for the purpose of text and data mining, under certain conditions.
                    Under these rules, rightsholders may choose to reserve their rights over their works or other
                    subject matter to prevent text and data mining, unless this is done for the purposes of scientific
                    research.
                    Where reservations of rights have been expressed in an appropriate manner, providers of
                    general-purpose AI models need to obtain an authorisation from rightsholders if they want to carry
                    out text and data mining over such works (see Recital 105 AI Act).</li>
            </ol>

            <p>Therefore, the Signatories of this Code commit to the following:</p>

            <div class="legal-text">
                <h4>TRANSPARENCY LEGAL TEXT</h4>
                <p><strong>Article 53(1), point (a) AI Act:</strong> "Providers of general-purpose AI models shall draw
                    up and keep up-to-date the technical documentation of the model, including its training and testing
                    process and the results of its evaluation, which shall contain, at a minimum, the information set
                    out in Annex XI for the purpose of providing it, upon request, to the AI Office and the national
                    competent authorities;"</p>

                <p><strong>Article 53(1), point (b) AI Act:</strong> "Providers of general-purpose AI models shall draw
                    up, keep up-to-date and make available information and documentation to providers of AI systems who
                    intend to integrate the general-purpose AI model into their AI systems. Without prejudice to the
                    need to observe and protect intellectual property rights and confidential business information or
                    trade secrets in accordance with Union and national law, the information and documentation shall:
                    <br>(i) enable providers of AI systems to have a good understanding of the capabilities and
                    limitations of the general-purpose AI model and to comply with their obligations pursuant to this
                    Regulation; and
                    <br>(ii) contain, at a minimum, the elements set out in Annex XII;"
                </p>

                <p><strong>Article 53(2) AI Act:</strong> "The obligations set out in paragraph 1, points (a) and (b),
                    shall not apply to providers of AI models that are released under a free and open-source licence
                    that allows for the access, usage, modification, and distribution of the model, and whose
                    parameters, including the weights, the information on the model architecture, and the information on
                    model usage, are made publicly available. This exception shall not apply to general-purpose AI
                    models with systemic risks."</p>

                <p><strong>Article 53(7) AI Act:</strong> "Any information or documentation obtained pursuant to this
                    Article, including trade secrets, shall be treated in accordance with the confidentiality
                    obligations set out in Article 78."</p>
            </div>

            <h3>Commitment 1. Documentation</h3>
            <p>In order to fulfil the obligations in Article 53(1), points (a) and (b) AI Act, Signatories commit to the
                Measures specified below. These Measures do not apply to providers of open-source AI models satisfying
                the conditions specified in Article 53(2) AI Act, unless the models are general-purpose AI models with
                systemic risk. For Signatories who are providers of general-purpose AI models with systemic risk,
                Measure 20.2 in this Code covers the additional documentation required by Article 53(1), point (a) AI
                Act (more specifically the documentation listed in Annex XI Section 2 AI Act).</p>

            <h4>Measure 1.1. Drawing up, keeping up-to-date, and providing the relevant information</h4>
            <p>Signatories commit to drawing up and providing the information listed in Table 1 below to the AI Office
                and national competent authorities upon request, and/or to downstream providers, with the disclosed
                information safeguarded by the trade secrets and confidentiality protections provided by Article 53(1),
                point (b), and (7) AI Act.</p>

            <p>Signatories are encouraged to consider whether the documented information can be disclosed, in whole or
                in part, to the public to promote public transparency. Some of this information may also be requested in
                summarised form as part of the public summary for training content that providers must make publicly
                available under Article 53(1), point (d) AI Act to be determined in a template to be provided by the AI
                Office.</p>

            <p>Signatories commit to ensuring that the documented information is reviewed and updated when necessary,
                including to reflect any changes to the general-purpose AI model.</p>

            <h4>Measure 1.2. Ensuring quality, integrity, and security of information</h4>
            <p>Signatories commit to ensuring that the documented information is controlled for quality and integrity,
                retained as evidence of compliance with obligations of the AI Act, and protected from unintended
                alterations.</p>

            <p>In the context of drawing-up, updating, and controlling the quality and security of the information and
                records, Signatories are encouraged to follow the established protocols and technical standards.</p>

            <div class="info-box">
                <h4>Appendix: Essential elements of an Acceptable Use Policy</h4>
                <p>An Acceptable Use Policy (AUP) is defined as guidelines to users on what is and is not considered
                    acceptable use.</p>

                <p>Essential elements of an AUP are:</p>
                <ul>
                    <li>A purpose statement explaining why the AUP exists;</li>
                    <li>The scope defining who the policy applies to and what resources it covers;</li>
                    <li>Main intended uses and users;</li>
                    <li>Acceptable uses, listing activities and tasks that are allowed, including high-risk AI uses
                        (within the meaning of Article 6 AI Act in conjunction with Annex I and III AI Act), if any,
                        that the model is intended to be integrated into;</li>
                    <li>Unacceptable uses, detailing forbidden actions (beyond those prohibited by Article 5 AI Act);
                    </li>
                    <li>Security measures containing a description of the security protocols that the users of the model
                        must follow;</li>
                    <li>If any monitoring of the use of their model is performed by the provider, an explanation of how
                        the monitoring occurs and its impact on users' privacy and confidentiality of users' business
                        information;</li>
                    <li>Warning processes and criteria for suspension or withdrawal of user privileges for not adhering
                        to the AUP;</li>
                    <li>Criteria for terminating user accounts and reference to applicable law and regulations for
                        enforcement;</li>
                    <li>Acknowledgement from users that they have read, understood, and agreed to comply with the AUP.
                    </li>
                </ul>
            </div>

            <h2>COPYRIGHT</h2>

            <h3>Whereas:</h3>
            <ol type="a">
                <li>Signatories recognise that general-purpose AI models and in particular large generative AI models ‚Äì
                    capable of generating text, images, and other content ‚Äì present unique innovation opportunities but
                    also challenges to artists, authors, and other creators, and to the way their creative content is
                    created, distributed, used, and consumed (Recital 105 AI Act). They further recognise that any use
                    of copyright protected content requires the authorisation of the rightsholder(s) concerned unless
                    relevant copyright exceptions and limitations apply (see Recital 105 AI Act).</li>

                <li>The AI Act and the Code are without prejudice to and shall be interpreted in accordance with Union
                    law on copyright and related rights. The Signatories recognise therefore that any use of copyright
                    protected content requires the authorisation of the rightsholder(s) concerned unless copyright
                    exceptions and limitations apply. The Signatories further recognise that copyright exceptions and
                    limitations shall only be applied in certain special cases which do not conflict with a normal
                    exploitation of the work or other subject-matter and do not unreasonably prejudice the legitimate
                    interests of the rightsholder.</li>

                <li>Directive (EU) 2019/790 introduced exceptions and limitations allowing, under certain conditions,
                    reproductions and extractions of works and other subject matter for the purpose of text and data
                    mining. Under these rules, rightsholders may choose to reserve their rights over their works and
                    other subject matter to prevent text and data mining, unless this is done for the purposes of
                    scientific research. Where reservation of rights has been expressly reserved in an appropriate
                    manner, providers of general-purpose AI models need to obtain an authorisation from rightsholders if
                    they want to carry out text and data mining over such works (Recital 105 AI Act).</li>

                <li>The Signatories recognise that, according to Art. 53(1), point (c), AI Act, any provider placing
                    general-purpose AIs on the Union market is obliged to put in place a policy to comply with Union law
                    on copyright and related rights, and in particular to identify and comply with, including through
                    state-of-the-art technologies, a reservation of rights expressed pursuant to Article 4(3) of
                    Directive (EU) 2019/790, regardless of the jurisdiction in which the copyright-relevant acts
                    underpinning the training of those general-purpose AI models take place (Recital 106 AI Act). This
                    Section aims to contribute to the proper application of this obligation (Article 56(1) AI Act) by
                    setting out a robust framework to ensure copyright compliance and transparency, while striking a
                    fair
                    balance between the various rights and legitimate interests at issue.<sup>1</sup> These measures
                    should be commensurate and proportionate to the type of model provider and take due account of the
                    interests of SMEs, including startups.<sup>2</sup></li>
            </ol>

            <p>Therefore, the Signatories of this Code commit to the following:</p>

            <div class="legal-text">
                <h4>LEGAL TEXT</h4>
                <p><strong>Article 53(1), point (c) AI Act:</strong> "Providers of general-purpose AI models shall put
                    in place a policy to comply with Union law on copyright and related rights, and in particular to
                    identify and comply with, including through state-of-the-art technologies, a reservation of rights
                    expressed pursuant to Article 4(3) of Directive (EU) 2019/790;"</p>
            </div>

            <h3>Commitment 2. Copyright policy</h3>
            <p>In order to fulfil the obligation to put in place a policy to comply with Union law on copyright and
                related rights, and in particular to identify and comply with, including through state-of-the-art
                technologies, a reservation of rights expressed pursuant to Article 4(3) of Directive (EU) 2019/790
                pursuant to Article 53(1), point (c) AI Act, Signatories commit to adopting the following measures:</p>

            <h4>Measure 2.1: Draw up and implement an internal copyright policy</h4>
            <p>Signatories commit to drawing up, keeping up-to-date, and implementing an internal policy to comply with
                Union law on copyright and related rights in accordance with the commitments of this Code, applicable to
                all phases of the development of a general-purpose AI model, including data collection, training,
                testing, and placing on the market, until a general-purpose AI model is definitively withdrawn from the
                Union market. Signatories commit to assigning responsibilities within their organisation for the
                implementation and overseeing of this policy.</p>

            <div class="kpi-box">
                <h5>Key Performance Indicators</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.1.1:</span> A single document approved by the Signatory that sets
                        out the internal copyright policy.</li>
                    <li><span class="kpi-target">KPI 2.1.2:</span> Documentation of changes to the copyright policy
                        (versioning).</li>
                    <li><span class="kpi-target">KPI 2.1.3:</span> Identification of the internal unit/person(s)
                        responsible for the implementation and overseeing of the copyright policy. This KPI does not
                        apply to SMEs.</li>
                </ul>
            </div>

            <div class="info-box">
                <p><sup>1</sup> See Articles 17(2), 16 and 13 CFEU and CJEU Judgment of 29 January 2008, Promusicae
                    (C-275/06, ECR 2008 p. I-271) ECLI:EU:C:2008:54, para 68; Judgment of 27 March 2014, UPC Telekabel
                    Wien (C-314/12) ECLI:EU:C:2014:192, para 46; Judgment of 26 April 2022, Poland / Parliament and
                    Council (C-401/19, Publi√© au Recueil num√©rique) ECLI:EU:C:2022:297, para 66.</p>
                <p><sup>2</sup> Recital 109 AI Act: "Without prejudice to Union copyright law, compliance with those
                    obligations should take due account of the size of the provider and allow simplified ways of
                    compliance for SMEs, including start-ups, that should not represent an excessive cost and not
                    discourage the use of such models".</p>
            </div>
            <h4>Measure 2.2: Publish a summary of the internal copyright policy</h4>
            <p>In order to provide public transparency about their policy to comply with Union copyright law,
                Signatories commit to making publicly available and keeping up to date a summary of their internal
                copyright policy, without prejudice to the need to observe and protect intellectual property rights and
                confidential business information or trade secrets in accordance with Union and national
                law.<sup>3</sup></p>

            <div class="kpi-box">
                <h5>Key Performance Indicator</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.2.1:</span> Summary of the up-to-date internal copyright policy
                        published on Signatory's website.</li>
                </ul>
            </div>

            <p class="footnote"><sup>3</sup> To be streamlined with the AI Office's template according to Article 53(1),
                point (d) AI Act.</p>

            <h4>Measure 2.3: Make reasonable efforts to assess the copyright compliance of third-party datasets</h4>
            <p>Signatories commit to undertaking a copyright due diligence when entering into an agreement with a third
                party when acquiring datasets for the purpose of the training of a general-purpose AI model. Signatories
                commit to making reasonable and proportionate efforts to obtain assurances from a third party about its
                compliance with Union law on copyright and related rights regarding a private, non-publicly accessible
                dataset, covering the following issues: the copyright status of data contained in the dataset, lawful
                access to such copyright-protected content, compliance with the limits of applicable exceptions or
                limitations, in particular Articles 3 and 4 of Directive (EU) 2019/790. Signatories commit to making
                reasonable and proportionate efforts to examine the plausibility of these assurances. In the absence of
                sufficient assurances, in particular in relation to publicly accessible datasets, Signatories commit to
                making reasonable and proportionate efforts to assess, on the basis of the description of the dataset
                and an analysis of random samples contained in the dataset, whether the dataset has been collected in
                compliance with Union law on copyright and related rights. This measure does not imply a commitment to
                verify or proceed to a work-by-work assessment of those datasets in terms of copyright compliance.</p>

            <div class="kpi-box">
                <h5>Key Performance Indicators</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.3.1:</span> Documentation of all assurances obtained in
                        accordance with this Measure.</li>
                    <li><span class="kpi-target">KPI 2.3.2:</span> Documentation of Signatory's copyright compliance
                        assessments. This KPI does not apply to SMEs.</li>
                </ul>
            </div>

            <h4>Measure 2.4: Ensure lawful access to copyright-protected content</h4>
            <p>If Signatories engage in text and data mining according to Article 2(2) of Directive (EU) 2019/790 for
                the training of their general-purpose AI models, they commit to making reasonable and proportionate
                efforts to ensure that they have lawful access to copyright-protected content in accordance with Article
                4(1) of Directive (EU) 2019/790.</p>

            <div class="kpi-box">
                <h5>Key Performance Indicator</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.4.1:</span> Documentation of the measures taken by the Signatory
                        to ensure lawful access to copyright-protected content. This KPI does not apply to SMEs.</li>
                </ul>
            </div>

            <h4>Measure 2.5: Do not crawl websites making available copyright-infringing content</h4>
            <p>Signatories commit to taking reasonable and proportionate measures to exclude widely known websites that
                make available to the public copyright-infringing content on a commercial scale and have no substantial
                legitimate uses ("piracy websites"<sup>4</sup>) from crawling activities for the training of their
                general-purpose AI models. Signatories are encouraged to take into account, as appropriate, relevant
                exclusion lists published by public authorities in the European Union and the European Economic Area and
                in the jurisdictions where they are established.</p>

            <p class="footnote"><sup>4</sup> Cf. the definition of a pirate website in "WIPO Advisory Committee on
                Enforcement, The building respect for intellectual property database project", WIPO/ACE/14/9, para 2
                (June 18, 2019).</p>

            <div class="kpi-box">
                <h5>Key Performance Indicator</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.5.1:</span> Documentation of the list of piracy websites excluded
                        from crawling. This KPI does not apply to SMEs.</li>
                </ul>
            </div>

            <h4>Measure 2.6: Respect Robot Exclusion Protocol</h4>
            <p>If Signatories engage in text and data mining according to Article 2(2) of Directive (EU) 2019/790 for
                the training of their general-purpose AI models, they commit, as a minimum measure to identify and
                comply with, including through state-of-the-art technologies, a reservation of rights expressed pursuant
                to Article 4(3) of Directive (EU) 2019/790, to employing web-crawlers that read and follow instructions
                expressed in accordance with the Robot Exclusion Protocol (robots.txt), as specified in the Internet
                Engineering Task Force (IETF) Request for Comments No. 9309. Signatories that also provide an online
                search engine as defined in Article 3(j) Regulation (EU) 2022/2065 or control such a provider are
                encouraged to take appropriate measures to ensure that the exclusion of a web-crawler that collects data
                for the training of general-purpose AI models pursuant to the Robot Exclusion Protocol does not
                negatively affect the findability of the content in their search engine.<sup>5</sup></p>

            <div class="kpi-box">
                <h5>Key Performance Indicator</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.6.1:</span> The name of any new or modified crawler as well as
                        the purpose of each crawler are specified in the copyright policy.</li>
                </ul>
            </div>

            <h4>Measure 2.7: Identify and comply with other appropriate expressions of rights reservations</h4>
            <p>Signatories commit to making best efforts that are proportionate to their size and capacities in
                accordance with widely used industry standards to identify and comply with, including through
                state-of-the-art technologies, other machine-readable means to appropriately express a rights
                reservation at source or work level pursuant to Article 4(3) of Directive (EU) 2019/790 in the case of
                content made publicly available online. This commitment is without prejudice to the right of affected
                rightsholders to expressly reserve the use of lawfully accessible works and other subject matter for the
                purposes of text and data mining in any appropriate manner pursuant to Article 4(3) of Directive
                2019/790/EU.</p>

            <p>In due consideration of relevant international and European standard-setting processes, Signatories are
                encouraged to support relevant standardisation efforts and engage on voluntary basis in bona fide
                discussions with other relevant stakeholders, including rightsholders, with the aim to develop
                interoperable machine-readable standards to express a rights reservation pursuant to Article 4(3) of
                Directive (EU) 2019/790 and to identify and comply with such rights reservation standards.</p>

            <div class="kpi-box">
                <h5>Key Performance Indicators</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.7.1:</span> List of other solutions for expressions of rights
                        reservations honoured by the Signatory is provided in the copyright policy, including
                        information on the period of time as of which these solutions have been honoured by the
                        Signatory.</li>
                    <li><span class="kpi-target">KPI 2.7.2:</span> Documentation of relevant standard-setting meetings
                        attended by the Signatory. This KPI does not apply to SMEs.</li>
                </ul>
            </div>

            <p class="footnote"><sup>5</sup> Recital 18, Dir. (EU) 2019/790: "Other uses should not be affected by the
                reservation of rights for the purposes of text and data mining."</p>

            <h4>Measure 2.8: Publish information on rights reservation compliance</h4>
            <p>Signatories commit to making public adequate information about the measures they adopt to identify and
                comply with rights reservations expressed pursuant to Article 4(3) of Directive (EU) 2019/790. That
                information includes, at a minimum, the name of all crawlers used by the Signatories or on their behalf
                for the collection of data for the training of a general-purpose AI model and the robots.txt features of
                those crawlers that are relevant for the expression of a rights reservation. Signatories commit to
                taking reasonable measures to enable affected rightsholders to obtain this information, for example by
                syndicating a web feed that covers every update of the website informing about the rights reservation
                compliance.<sup>6</sup></p>

            <div class="kpi-box">
                <h5>Key Performance Indicator</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.8.1:</span> Information about the measures adopted to respect the
                        reservation of rights made public on the website of the Signatory.<sup>7</sup></li>
                </ul>
            </div>

            <h4>Measure 2.9: Prevent copyright-related overfitting</h4>
            <p>Signatories that train a generative general-purpose AI model that will allow for the flexible generation
                of content, such as in the form of text, audio, images or video,<sup>8</sup> commit to making best
                efforts to prevent an overfitting of their general-purpose AI model in order to mitigate the risk that a
                downstream AI system, into which the general-purpose AI model is integrated, generates copyright
                infringing output that is identical or recognisably similar to protected works used in the training
                stage. This commitment applies irrespective of whether a Signatory vertically integrates the model into
                its own AI system(s) or whether the model is provided to another entity based on contractual relations.
            </p>

            <div class="kpi-box">
                <h5>Key Performance Indicator</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.9.1:</span> Documentation of the measures taken by the Signatory
                        to avoid overfitting in the copyright policy. This KPI does not apply to SMEs.</li>
                </ul>
            </div>

            <h4>Measure 2.10: Prohibit copyright-infringing uses of the model</h4>
            <p>In order to further mitigate the risk that a downstream AI system, into which a generative
                general-purpose AI model is integrated, generates copyright infringing output, Signatories commit to
                prohibiting copyright-infringing uses of their model in their acceptable use policy, terms and
                conditions, or other equivalent documents.</p>

            <div class="kpi-box">
                <h5>Key Performance Indicator</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.10.1:</span> Acceptable use policy, terms and conditions, or
                        other equivalent documents include a prohibition of copyright-infringing uses.</li>
                </ul>
            </div>

            <p class="footnote"><sup>6</sup> To be streamlined with the AI Office's template according to Article 53(1),
                point (d) AI Act.</p>
            <p class="footnote"><sup>7</sup> To be streamlined with the AI Office's template according to Article 53(1),
                point (d) AI Act.</p>
            <p class="footnote"><sup>8</sup> See Recital 90 AI Act specifying generative AI models as a type of
                general-purpose AI models.</p>

            <h4>Measure 2.11: Designate a point of contact</h4>
            <p>Signatories commit to designating a point of contact for communication with affected rightsholders.</p>

            <p>Signatories commit to enabling affected rightsholders to lodge, by electronic means, sufficiently precise
                and adequately substantiated complaints concerning the unauthorised use of their specific works or other
                protected subject matter for the training of a general-purpose AI model, where no relevant exception
                under Union law applies. Signatories may adopt appropriate measures to prevent the frequent submission
                of complaints that are manifestly unfounded. The commitment to enable rightsholders to lodge complaints
                does not apply to SMEs.</p>

            <div class="kpi-box">
                <h5>Key Performance Indicators</h5>
                <ul class="kpi-list">
                    <li><span class="kpi-target">KPI 2.11.1:</span> Designation of the point of contact and publication
                        of adequate and easily accessible information about the point of contact.</li>
                    <li><span class="kpi-target">KPI 2.11.2:</span> Internal process to adequately handle
                        copyright-related complaints specified in the copyright policy. Publication of the possibility
                        to lodge copyright-related complaints on the website of the Signatory. This KPI does not apply
                        to SMEs.</li>
                </ul>
            </div>

        </section>

        <!-- Glossary Section -->
        <section class="glossary" id="glossary" role="complementary" aria-label="Glossary">
            <h2>Glossary</h2>
            <dl class="glossary-list">
                <dt id="term-documentation">documentation</dt>
                <dd>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut
                    labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation.</dd>

                <dt id="term-code">Code</dt>
                <dd>Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
                    pariatur. Excepteur sint occaecat cupidatat non proident.</dd>

                <dt id="term-commitments">Commitments</dt>
                <dd>Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque
                    laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis.</dd>

                <dt id="term-model">model</dt>
                <dd>At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum
                    deleniti atque corrupti quos dolores et quas molestias excepturi.</dd>

                <dt id="term-framework">Framework</dt>
                <dd>Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod
                    maxime placeat facere possimus, omnis voluptas assumenda est.</dd>
            </dl>
        </section>

        <!-- Full Recitals Section -->
        <section class="recitals-full" id="recitals" role="complementary" aria-label="Full recitals">
            <h2>Recitals</h2>
        </section>
    </article>

    <script src="script.js"></script>
</body>

</html>