<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0">
    <title>EU AI Act Code of Practice</title>
    <link rel="stylesheet" href="https://edwardtufte.github.io/tufte-css/tufte.css" />
    <link rel="stylesheet" href="styles.css" />
</head>

<body>
    <article role="main">
        <!-- Navigation toggle -->
        <button class="nav-toggle" aria-expanded="false" aria-controls="side-nav" aria-label="Toggle navigation menu">
            <span class="nav-icon" aria-hidden="true">&#9776;</span>
            <span class="nav-label">Table of Contents</span>
        </button>

        <!-- Navigation -->
        <nav id="side-nav" class="side-nav" role="navigation" aria-label="Table of contents">
            <div class="nav-controls">
                <div class="theme-control">
                    <label for="theme-select">Theme:</label>
                    <select id="theme-select" aria-label="Select color theme">
                        <option value="system">üñ•Ô∏è System Default</option>
                        <option value="light">‚òÄÔ∏è Light</option>
                        <option value="dark">üåô Dark</option>
                    </select>
                </div>
            </div>
            <div class="keyboard-shortcuts" aria-label="Keyboard shortcuts">
                <h4>Keyboard Shortcuts</h4>
                <ul>
                    <li><kbd>‚Üë</kbd>/<kbd>‚Üì</kbd> Navigate headlines</li>
                    <li><kbd>‚Üê</kbd>/<kbd>‚Üí</kbd> Navigate commitments</li>
                    <li><kbd>1</kbd>To top<kbd>2</kbd>To glossary<kbd>3</kbd>To recitals</li>
                    <li><kbd>4</kbd>Toggle all recitals</li>
                </ul>
            </div>
            <div id="nav-content" class="nav-content">
                <h3>Contents</h3>
            </div>
        </nav>

        <h1>EU AI Act Code of Practice</h1>

        <section class="main-content" aria-label="Main content">
            <p class="subtitle">Second Draft - 19/12/2024</p>

            <div class="disclaimer-box" role="complementary" aria-label="Important disclaimer">
                <h4>IMPORTANT DISCLAIMER & HOW TO CONTRIBUTE</h4>
                <p>This is a free, best-effort service to make the EU AI Act Code of Practice more accessible to
                    stakeholders. While we strive
                    for accuracy, this is NOT an official source.</p>

                <p><strong>Please always refer to the <a
                            href="https://digital-strategy.ec.europa.eu/en/library/second-draft-general-purpose-ai-code-practice-published-written-independent-experts">official
                            PDF document</a> for the authoritative version.</strong> Any discrepancies between this
                    version and the official document should be considered errors on our part.</p>

                <p>Help us improve:</p>
                <ul>
                    <li>Report errors via email: <a
                            href="mailto:alexander.zacherl@googlemail.com">alexander.zacherl@googlemail.com</a></li>
                    <li>Submit a pull request on <a href="https://github.com/yourusername/cop-reader">GitHub</a></li>
                </ul>
            </div>

            <h2>Commitment 21. Public transparency</h2>

            <div class="recital" role="region" aria-expanded="true">
                <h4 role="button" tabindex="0" aria-controls="recital-1-content">Recital</h4>
                <div id="recital-1-content">
                    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut
                        labore
                        et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi
                        ut
                        aliquip ex ea commodo consequat.</p>
                </div>
            </div>

            <p>Signatories commit to offering appropriate public transparency with the aim of aiding the wider
                ecosystem, including the public and external researchers, to better understand and mitigate systemic
                risks stemming from general-purpose AI models, especially in
                light of the nascency of the science of assessing and mitigating systemic risks.</p>

            <div class="recital" role="region" aria-expanded="true">
                <h4 role="button" tabindex="0" aria-controls="recital-2-content">Recital</h4>
                <div id="recital-2-content">
                    <p>Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
                        pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt
                        mollit
                        anim id est laborum.</p>
                </div>
            </div>

            <p>At a minimum, Signatories commit to publishing their Framework and their Model Reports or similar
                documents (such as model cards or system cards). Information may be redacted where its inclusion would
                substantially increase systemic risk, such as the disclosure of information about safety mitigations
                that would undermine their effectiveness or divulge sensitive commercial information to a degree
                disproportionate to the societal benefit.</p>

            <!-- Example of Legal Text Box -->
            <div class="legal-text" role="complementary" aria-label="Legal text">
                <h4>LEGAL TEXT</h4>
                <p>Article 55(1), point (a) AI Act: "Providers of general-purpose AI models shall draw up and keep
                    up-to-date the technical documentation of
                    the model, including its training and testing process and
                    the results of its evaluation, which shall contain, at a minimum, the information set out in Annex
                    XI for the purpose of providing it, upon request, to the AI Office and the national competent
                    authorities;"</p>
            </div>

            <h3>Considerations based on Article 3(65) AI Act:</h3>
            <ul>
                <li>Specific to high-impact capabilities of general-purpose AI models
                    <ul>
                        <li>High velocity</li>
                        <li>Compounding or cascading</li>
                        <li>Irreversibility</li>
                    </ul>
                </li>
                <li>Significant impact</li>
                <li>Due to reach, or due to actual or reasonably foreseeable negative effects on:
                    <ul>
                        <li>public health</li>
                        <li>safety</li>
                        <li>public security</li>
                        <li>fundamental rights</li>
                        <li>society as a whole</li>
                    </ul>
                </li>
            </ul>

            <div class="recital" role="region" aria-expanded="true">
                <h4 role="button" tabindex="0" aria-controls="recital-3-content">Recital</h4>
                <div id="recital-3-content">
                    <p>Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium,
                        totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae
                        dicta sunt explicabo.</p>
                </div>
            </div>

            <!-- Example of Information Box -->
            <div class="info-box" role="complementary" aria-label="Information from AI office">
                <h4>INFORMATION BOX FROM THE AI OFFICE</h4>
                <p>Article 56 AI Act states that the Code will include
                    the "identification of the type and nature of the
                    systemic risks at Union level, including their sources, where appropriate"</p>
            </div>

            <h3>Potential Key Performance Indicators</h3>
            <ul class="kpi-list">
                <li><strong>KPI 21.1:</strong> Signatories publish updated or new versions of their Frameworks within 15
                    working days of sending it to the AI Office. <span class="kpi-target">(target: 100%)</span></li>
                <li><strong>KPI 21.2:</strong> Signatories publish Model Reports within five days after the relevant
                    model is released on the EU market. <span class="kpi-target">(target: 100%)</span></li>
            </ul>

            <h3>Whereas:</h3>
            <ol type="a" class="whereas-list">
                <li>The Signatories recognise the particular role and responsibility of providers of general-purpose AI
                    models along the AI value chain</li>
                <li>The Signatories recognise that in the case of a modification or fine-tuning of a model, the
                    obligations for providers should be limited to that modification or fine-tuning to safeguard
                    proportionality</li>
            </ol>

            <!-- Example of Explanatory Box -->
            <div class="explanatory-box" role="complementary" aria-label="Explanation of changes">
                <h4>Explanation of changes to Commitment 21:</h4>
                <p>This Commitment was revised following provider feedback that publishing Model Reports was overly
                    burdensome and goes beyond the requirements of the AI Act. To address concerns, we eased disclosure
                    requirements, allowing the redaction of sensitive commercial information where societal benefits are
                    minimal.</p>
            </div>

            <p>This Code establishes a comprehensive framework for the development and deployment of
                general-purpose AI systems. The model providers must
                maintain detailed documentation throughout the development process.</p>

            <p>The framework outlined in this document ensures that each model adheres to the specified commitments.</p>

            <h2>Commitment 4. Safety and Security Framework</h2>

            <p>In order to fulfil their obligations under Article 55(1) AI Act, Signatories commit to adopting,
                implementing, and making available to the AI Office a Safety and Security Framework (also referred to as
                the Framework). The Framework will apply to all general-purpose AI models with systemic risk that a
                Signatory develops or deploys.</p>

            <div class="info-box" role="complementary" aria-label="Framework outline">
                <h4>Potential outline of a Safety and Security Framework</h4>
                <ol>
                    <li>Risk tiers and mapping to technical risk mitigations (Measures 4.2‚Äî4.5)</li>
                    <li>Risk assessment (Commitments 6‚Äî10)</li>
                    <li>More detailed descriptions of technical risk mitigations (Commitments 11‚Äî12)</li>
                    <li>Development and deployment decisions (Commitment 13)</li>
                    <li>Governance risk mitigations (Commitments 14‚Äî21)</li>
                </ol>
            </div>

            <h3>Measure 4.1. Procedures</h3>
            <p>Signatories commit to systematically documenting in their Framework the actions, decisions, and
                procedures adopted to comply with Commitments 6‚Äî21.</p>

            <div class="kpi-box">
                <h5>Potential Key Performance Indicator</h5>
                <ul class="kpi-list">
                    <li><strong>KPI 4.1.1:</strong> Percentage of Commitments 6‚Äî21 that have procedures detailed in the
                        Framework <span class="kpi-target">(target: 100%)</span></li>
                </ul>
            </div>

            <h3>Measure 4.2. Risk tiers</h3>
            <p>Signatories commit to describing and justifying risk tiers in their Framework for each systemic risk they
                identify as per Commitment 6. Such tiers will form the basis for their risk assessment (Commitments
                7‚Äî10) and risk mitigation decisions (Commitments 11‚Äî12).</p>

            <div class="kpi-box">
                <h5>Potential Key Performance Indicator</h5>
                <ul class="kpi-list">
                    <li><strong>KPI 4.2.1:</strong> Percentage of identified risks that have an unacceptable risk tier
                        defined, with an explanation of how they were chosen <span class="kpi-target">(target:
                            100%)</span></li>
                </ul>
            </div>

            <h2>Commitment 5. Safety and Security Model Reports</h2>

            <p>In order to fulfil their obligations under Article 53(1), point (a), and Article 55(1) AI Act,
                Signatories commit to providing transparency to the AI Office about the application of their Framework
                to the development and deployment of general-purpose AI models with systemic risk.</p>

            <h3>Measure 5.1. Level of detail</h3>
            <p>Signatories commit to ensuring that the level of detail in a Model Report:</p>
            <ol type="a">
                <li>Is proportionate to the highest risk tier that the model reaches, or that the Signatory expects it
                    to reach during its development and deployment lifecycle</li>
                <li>Would allow for AI Office assessment of the methods used for risk assessment and mitigation</li>
            </ol>

            <h3>Measure 5.2. Results of risk assessment and mitigation</h3>
            <p>Signatories commit to including in a Model Report the results of risk assessment undertaken for the model
                throughout its development and deployment lifecycle, in line with Commitments 6‚Äî10.</p>

            <div class="kpi-box">
                <h5>Potential Key Performance Indicators</h5>
                <ul class="kpi-list">
                    <li><strong>KPI 5.2.1:</strong> Percentage of identified systemic risks for which the Model Report
                        compares the assessed risk of the model both with and without safety and security mitigations
                        <span class="kpi-target">(target: 100%)</span>
                    </li>
                    <li><strong>KPI 5.2.2:</strong> Percentage of documented deviations from rigour in risk assessment
                        that include a detailed technical description and assessment of the potential impact on the
                        integrity of results</li>
                </ul>
            </div>

            <h2>Commitment 6. Risk assessment and mitigation along the model lifecycle</h2>

            <p>To fulfil their obligations under Article 55(1) AI Act, Signatories commit to assessing and mitigating
                systemic risks during the entire lifecycle of their general-purpose AI model with systemic risk and to
                performing a risk management process at the key points of the model lifecycle.</p>

            <h3>Measure 6.1. Before training</h3>
            <p>Potentially during the design and prototyping phases, but at the latest before starting a final training
                run for a general-purpose AI model with systemic risk, Signatories commit to assessing and potentially
                mitigating systemic risks with a focus on preparation, forecasting and security mitigations.</p>

            <h3>Measure 6.2. During training</h3>
            <p>During training and post-training enhancements, Signatories commit to assessing and potentially
                mitigating systemic risks at pre-defined milestones at which the model could potentially become
                significantly more capable.</p>

            <h3>Measure 6.4. During deployment</h3>
            <p>During the deployment of a general-purpose AI model with systemic risk (internally and externally),
                Signatories commit to periodically assessing and potentially mitigating systemic risks.</p>

            <div class="kpi-box">
                <h5>Potential Key Performance Indicators</h5>
                <ul class="kpi-list">
                    <li><strong>KPI 6.4.1:</strong> Percentage of evaluations re-run at a 6-monthly frequency, which are
                        relevant for the highest risk tier <span class="kpi-target">(target: 100%)</span></li>
                    <li><strong>KPI 6.4.2:</strong> Percentage of evaluations re-run at a 6-month frequency, which are
                        relevant for lower risk tiers <span class="kpi-target">(target: 50%)</span></li>
                </ul>
            </div>

            <div class="explanatory-box" role="complementary" aria-label="Explanation of changes">
                <h4>Explanation of changes to Commitments 7‚Äî9 (Risk identification, analysis and evaluation):</h4>
                <p>Our primary goal for this draft was to ensure that the Measures align closely with existing standards
                    in risk management. At the same time, we aim to avoid prescribing an overly fixed process that is
                    not suitable for the unique challenges presented by general-purpose AI models with systemic risk.
                </p>
            </div>
        </section>

        <!-- Glossary Section -->
        <section class="glossary" id="glossary" role="complementary" aria-label="Glossary">
            <h2>Glossary</h2>
            <dl class="glossary-list">
                <dt id="term-documentation">documentation</dt>
                <dd>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut
                    labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation.</dd>

                <dt id="term-code">Code</dt>
                <dd>Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
                    pariatur. Excepteur sint occaecat cupidatat non proident.</dd>

                <dt id="term-commitments">Commitments</dt>
                <dd>Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque
                    laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis.</dd>

                <dt id="term-model">model</dt>
                <dd>At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum
                    deleniti atque corrupti quos dolores et quas molestias excepturi.</dd>

                <dt id="term-framework">Framework</dt>
                <dd>Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod
                    maxime placeat facere possimus, omnis voluptas assumenda est.</dd>
            </dl>
        </section>

        <!-- Full Recitals Section -->
        <section class="recitals-full" id="recitals" role="complementary" aria-label="Full recitals">
            <h2>Recitals</h2>
        </section>
    </article>

    <script src="script.js"></script>
</body>

</html>